!apt update

# Install jdk8
!apt-get install openjdk-8-jdk-headless -qq > /dev/null
# Set jdk environment path which enables you to run Pyspark in your Colab environment.
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java

!apt-get install maven

from google.colab import drive
drive.mount('/content/gdrive/')

%cd /content/gdrive/My Drive/Work

!chmod 775 -R extraction-framework

%cd extraction-framework

#before istallation, change the settings for persian:
#in .../core/src/main/resources/universal : change the language to "fa", change the address of basedir & logdir to the address of the directoris you made.
#in ../dump chage the language of download & extractions files to "fa" ad delete unnecessary languages

!mvn clean install

/content/gdrive/MyDrive/Work/extraction-framework/basedir

!run download download.10000.properties
#there is a high chance of getting an error in the extraction process; if so,delete all of the downloaded files with ".download_complete" suffix and rerun the extraction process.
#extraction.mappings & extraction.spark are recommended for the extraction step.

!run extraction extraction.spark.properties

#after extraction there will be some ".bz2" files containing the output of extraction (.ttl RDF files) in basedir; 
#if you work in windows you wount be able to unzip these files, However you can use some online websites for this purpose.
#after that you need to view your ".ttl" file. there are plenty of websites that convert ".ttl" files to ".xml". 
#at last you can build a graph frome these ".xml" files in python.